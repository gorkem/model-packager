name: Convert models from HF to GGUF

on:
    workflow_dispatch:
 
jobs:
    convert-model:
        runs-on: ubuntu-latest
        strategy:
            matrix:
                model:
                    - repo: meta-llama/Llama-2-7b-chat
                      name: llama-2
                      variant: 7b-chat
                      description: "Llama 2 7b chat model"
                      kitfile-template: ./kitfiles/llama2.yml

        env:
            HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        steps:
            - name: Clean runner image
              run: |
                echo "Before removing files:"
                df -h
                sudo rm -rf /usr/share/dotnet
                sudo rm -rf /opt/ghc
                sudo rm -rf "/usr/local/share/boost"
                sudo rm -rf "$AGENT_TOOLSDIRECTORY"
                echo "After removing files:"
                df -h
            - uses: actions/checkout@v4
              with:
                fetch-depth: 0
            - uses: actions/setup-python@v5
              with:
                python-version: '3.10'
            - name: Install dependencies
              run: ./scripts/check-deps
            - name: check diskspace after deps
              run: | 
                echo "After dependencies are installed:"
                df -h
            - name: download model
              run: ./scripts/hf-clone ${{ matrix.model.repo }} ./model
            - name: check diskspace after download
              run: | 
                echo "After dependencies are installed:"
                df -h
            - name: convert model to gguf
              run: ./scripts/conv-to-gguf ./model ./model/${{matrix.model.name}}-${{matrix.model.variant}}.gguf
            - name: push model to artifacts
              uses: actions/upload-artifact@v2
              with:
                name: ${{matrix.model.name}}-${{matrix.model.variant}}
                path: ./model/
    call-quantize:
        needs: convert-model
        strategy:
            matrix:
                model:
                    - repo: meta-llama/Llama-2-7b-chat
                      name: llama-2-7b-chat

        uses: ./.github/workflows/quantize-and-pack.yml
        with:
            model-name: ${{matrix.model.name}}
            model-variant: ${{matrix.model.variant}}
            model-description: ${{matrix.model.description}}
            kitfile-template: ${{matrix.model.kitfile-template}}

        
                